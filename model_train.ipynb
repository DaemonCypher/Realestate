{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from database_helper import *\n",
    "from collections import Counter\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from datetime import datetime\n",
    "\n",
    "def prepare_data(city):\n",
    "    \"\"\"Fetch and prepare data for a given city from the SQLite database.\"\"\"\n",
    "    \n",
    "    # Connect to the SQLite database\n",
    "    conn = sqlite3.connect(\"validAddress.db\")\n",
    "    \n",
    "    # Fetch data from the database\n",
    "    results = fetch_city_from_db(conn, 'validAddress', city)\n",
    "    \n",
    "    # Determine the most common history length\n",
    "    most_common_length = Counter(len(row[3]) for row in results).most_common(1)[0][0]\n",
    "    \n",
    "    # Create headers for the DataFrame\n",
    "    data_date_dt = datetime.strptime(results[0][6], '%Y-%m-%d %H:%M:%S.%f')\n",
    "    header = ['Address'] + [(data_date_dt - relativedelta(months=i)).strftime('%Y-%m') for i in range(most_common_length - 1, -1, -1)]\n",
    "    \n",
    "    # Transform results\n",
    "    modified_results = [(address, *history) for id, address, city, history, status, status_date, data_date, beds, baths, year_built, sqft in results if len(history) == most_common_length]\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    data = pd.DataFrame(modified_results, columns=header)\n",
    "    \n",
    "    conn.close()\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(data,city):\n",
    "    \"\"\"Train a 1D CNN model on the provided data and return evaluation metrics and predictions.\"\"\"\n",
    "    \n",
    "    # Extract addresses and prepare data\n",
    "    addresses = data['Address']\n",
    "    data = data.drop(columns=['Address'])\n",
    "    X = data.values[:, :-1].reshape((-1, data.shape[1]-1, 1))\n",
    "    y = data.values[:, -1]\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Define and compile the model\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "        tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=20, batch_size=64, validation_data=(X_test, y_test))\n",
    "    \n",
    "    # Evaluate and predict\n",
    "    loss, mae = model.evaluate(X_test, y_test, verbose=0)\n",
    "    y_pred = model.predict(X_test)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    predicted_next_month_prices = model.predict(X)\n",
    "    \n",
    "    # Prepare results\n",
    "    predicted_prices_df = pd.DataFrame({\n",
    "        'Address': addresses,\n",
    "        'Predicted_Next_Month_Price': predicted_next_month_prices.flatten()\n",
    "    })\n",
    "    #model.save(f\"saved_model/{city}-model\")\n",
    "    return mae, r2, predicted_prices_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is used to trial different vairables for ML model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "34/34 [==============================] - 1s 8ms/step - loss: 12786328576.0000 - mae: 77434.8594 - val_loss: 1337160192.0000 - val_mae: 29206.8438\n",
      "Epoch 2/20\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 748081216.0000 - mae: 16984.6113 - val_loss: 594594880.0000 - val_mae: 15737.7256\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 576699904.0000 - mae: 15072.4482 - val_loss: 415088416.0000 - val_mae: 12253.1855\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 411784448.0000 - mae: 12487.2129 - val_loss: 365734208.0000 - val_mae: 12563.8057\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 341862816.0000 - mae: 11568.8428 - val_loss: 262023024.0000 - val_mae: 9947.4678\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 263249568.0000 - mae: 10219.6016 - val_loss: 218320576.0000 - val_mae: 8965.9844\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 212193456.0000 - mae: 9353.6699 - val_loss: 191808720.0000 - val_mae: 8367.4131\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 163037504.0000 - mae: 8109.1455 - val_loss: 203983744.0000 - val_mae: 9388.8428\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 209177248.0000 - mae: 10361.3438 - val_loss: 217729696.0000 - val_mae: 10378.0391\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 162608560.0000 - mae: 8719.2754 - val_loss: 167976592.0000 - val_mae: 8281.5195\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 127497080.0000 - mae: 7544.9121 - val_loss: 164500400.0000 - val_mae: 9277.4570\n",
      "Epoch 12/20\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 134499840.0000 - mae: 8109.5547 - val_loss: 252873280.0000 - val_mae: 11914.0723\n",
      "Epoch 13/20\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 136788096.0000 - mae: 8380.0410 - val_loss: 239688800.0000 - val_mae: 12768.5117\n",
      "Epoch 14/20\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 124584736.0000 - mae: 7662.8276 - val_loss: 121143632.0000 - val_mae: 6589.8174\n",
      "Epoch 15/20\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 94413112.0000 - mae: 6395.0952 - val_loss: 109327024.0000 - val_mae: 6333.8818\n",
      "Epoch 16/20\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 90261664.0000 - mae: 6191.3838 - val_loss: 140575456.0000 - val_mae: 7662.6533\n",
      "Epoch 17/20\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 99778584.0000 - mae: 6858.0557 - val_loss: 116196400.0000 - val_mae: 6545.0483\n",
      "Epoch 18/20\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 109790744.0000 - mae: 7454.1895 - val_loss: 112755528.0000 - val_mae: 7234.4268\n",
      "Epoch 19/20\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 114469960.0000 - mae: 7647.6929 - val_loss: 107145064.0000 - val_mae: 6841.1157\n",
      "Epoch 20/20\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 110733264.0000 - mae: 7462.2070 - val_loss: 121234688.0000 - val_mae: 6836.1948\n",
      "17/17 [==============================] - 0s 2ms/step\n",
      "85/85 [==============================] - 0s 1ms/step\n",
      "6836.19482421875 0.9926778869820354\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def ml_setup(city):\n",
    "    name=city.lower()\n",
    "    data = prepare_data(name)\n",
    "    mae, r2, predictions = train_model(data)\n",
    "    print(mae,r2)\n",
    "    \n",
    "    \n",
    "ml_setup(\"berlin\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
